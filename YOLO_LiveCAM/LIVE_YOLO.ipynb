{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66639778",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "import pyrealsense2 as rs\n",
    "import numpy as np\n",
    "\n",
    "class DepthCamera:\n",
    "    def __init__(self):\n",
    "        # Configure depth and color streams\n",
    "        self.pipeline = rs.pipeline()\n",
    "        config = rs.config()\n",
    "\n",
    "        # Get device product line for setting a supporting resolution\n",
    "        pipeline_wrapper = rs.pipeline_wrapper(self.pipeline)\n",
    "        pipeline_profile = config.resolve(pipeline_wrapper)\n",
    "        device = pipeline_profile.get_device()\n",
    "        device_product_line = str(device.get_info(rs.camera_info.product_line))\n",
    "\n",
    "        config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)\n",
    "        config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)\n",
    "\n",
    "\n",
    "        # Start streaming\n",
    "        self.pipeline.start(config)\n",
    "\n",
    "    def get_frame(self):\n",
    "        frames = self.pipeline.wait_for_frames()\n",
    "        depth_frame = frames.get_depth_frame()\n",
    "        color_frame = frames.get_color_frame()\n",
    "\n",
    "        depth_image = np.asanyarray(depth_frame.get_data())\n",
    "        color_image = np.asanyarray(color_frame.get_data())\n",
    "        if not depth_frame or not color_frame:\n",
    "            return False, None, None\n",
    "        return True, depth_image, color_image\n",
    "\n",
    "    def release(self):\n",
    "        self.pipeline.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c07ca38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "model_path = os.getenv('HOME') + '/aiffel/darknet-master/yolov4.weights'\n",
    "list_path = os.getenv('HOME') + '/aiffel/darknet-master/cfg/yolov4.cfg'\n",
    "name_path = os.getenv('HOME') + '/aiffel/darknet-master/data/coco.names'\n",
    "\n",
    "YOLO_net = cv2.dnn.readNet(model_path, list_path)\n",
    "\n",
    "classes = []\n",
    "with open(name_path, \"r\") as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "layer_names = YOLO_net.getLayerNames()\n",
    "output_layers = [layer_names[i[0] - 1] for i in YOLO_net.getUnconnectedOutLayers()]\n",
    "colors = np.random.uniform(0, 255, size=(len(classes), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90d096d2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cup\n",
      "mouse\n",
      "person\n",
      "154\n",
      "cup\n",
      "mouse\n",
      "person\n",
      "154\n",
      "cup\n",
      "mouse\n",
      "person\n",
      "154\n",
      "mouse\n",
      "cup\n",
      "mouse\n",
      "mouse\n",
      "person\n",
      "154\n",
      "keyboard\n",
      "cup\n",
      "mouse\n",
      "mouse\n",
      "person\n",
      "154\n",
      "keyboard\n",
      "cup\n",
      "mouse\n",
      "mouse\n",
      "person\n",
      "154\n",
      "cup\n",
      "mouse\n",
      "mouse\n",
      "person\n",
      "154\n",
      "mouse\n",
      "cup\n",
      "mouse\n",
      "person\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "min() arg is an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-c4ad6fb40b07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mROI\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mROI\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0;31m#if(len(ROI) != 0):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: min() arg is an empty sequence"
     ]
    }
   ],
   "source": [
    "# Initialize Camera Intel Realsense\n",
    "dc = DepthCamera()\n",
    "\n",
    "def show_loc(x, y):\n",
    "    cv2.circle(color_frame, (x, y), 4, (0, 0, 255))\n",
    "    \n",
    "    distance = depth_frame[y, x]\n",
    "    cv2.putText(color_frame, \"{}mm\".format(distance), (x, y + 20), cv2.FONT_HERSHEY_PLAIN, 2, (0, 0, 0), 2)\n",
    "\n",
    "while True:\n",
    "    # 웹캠 프레임\n",
    "    ret, depth_frame, color_frame = dc.get_frame()\n",
    "    h, w, c = color_frame.shape\n",
    "\n",
    "    # YOLO 입력\n",
    "    blob = cv2.dnn.blobFromImage(color_frame, 0.00392, (640, 480), (0, 0, 0), True, crop=False)\n",
    "    YOLO_net.setInput(blob)\n",
    "    outs = YOLO_net.forward(output_layers)\n",
    "\n",
    "    class_ids = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "\n",
    "    for out in outs:\n",
    "\n",
    "        for detection in out:\n",
    "\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "\n",
    "            if confidence > 0.5:\n",
    "                # Object detected\n",
    "                center_x = int(detection[0] * w)\n",
    "                center_y = int(detection[1] * h)\n",
    "                dw = int(detection[2] * w)\n",
    "                dh = int(detection[3] * h)\n",
    "                # Rectangle coordinate\n",
    "                x = int(center_x - dw / 2)\n",
    "                y = int(center_y - dh / 2)\n",
    "                boxes.append([x, y, dw, dh])\n",
    "                confidences.append(float(confidence))\n",
    "                class_ids.append(class_id)\n",
    "\n",
    "    indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.45, 0.4)\n",
    "\n",
    "\n",
    "    for i in range(len(boxes)):\n",
    "        if i in indexes:\n",
    "            x, y, w, h = boxes[i]\n",
    "\n",
    "            label = str(classes[class_ids[i]])\n",
    "            score = confidences[i]\n",
    "            \n",
    "            print(label)\n",
    "            \n",
    "            if label == 'person':\n",
    "\n",
    "                # 경계상자와 클래스 정보 이미지에 입력\n",
    "                cv2.rectangle(color_frame, (x, y), (x + w, y + h), (0, 0, 255), 5)\n",
    "                cv2.putText(color_frame, label, (x, y - 20), cv2.FONT_ITALIC, 0.5, (255, 255, 255), 1)\n",
    "                \n",
    "                ROI = depth_frame[y:y+h,x:x+w]\n",
    "                \n",
    "                \n",
    "                print(min(ROI[ROI>0]))\n",
    "                \n",
    "                #if(len(ROI) != 0):\n",
    "                #    print(min(ROI[ROI>0])\n",
    "            \n",
    "                c_x = x + w//2\n",
    "                c_y = y + h//2\n",
    "                show_loc(c_x, c_y)\n",
    "\n",
    "    cv2.imshow(\"YOLOv4\", color_frame)\n",
    "    #cv2.imshow(\"YOLOv4_lenght\", depth_frame)\n",
    "\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:\n",
    "        dc.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd084e62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
